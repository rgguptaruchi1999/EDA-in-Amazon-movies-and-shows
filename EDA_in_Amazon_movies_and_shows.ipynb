{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Project Name : Exploratory Data Analysis of IMDB Data and Movies"
      ],
      "metadata": {
        "id": "CyxuJgjn6aCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Summary:\n",
        "\n",
        "This project aims to perform an exploratory data analysis (EDA) on a dataset containing information\n",
        "about movies and TV shows listed on IMDB and available on Amazon Prime Video. The analysis will involve\n",
        "cleaning and processing the data, visualizing key attributes such as genres, ratings, release years, and the\n",
        "distribution of movies versus TV shows. The goal is to uncover insights into the content available on Amazon Prime Video,\n",
        "identify trends, and potentially understand audience preferences based on the provided data. The steps will likely include data loading,\n",
        "handling missing values, data type conversions, creating visualizations using libraries like Matplotlib and Seaborn, and summarizing the findings.\n",
        "\n",
        "There are some key steps:\n",
        "##describtion for data collection and cleaning\n",
        "\n",
        "   Data Collection: The dataset will be loaded from a CSV file (`amazon_prime_titles.csv`). This file contains information about\n",
        "        various movies and TV shows on Amazon Prime Video, including details like title, type (movie or TV show), genre, release year, rating, and other relevant metadata.\n",
        "   Data Cleaning and Preprocessing:\n",
        "      Handling Missing Values: Identify and address missing values in relevant columns. Depending on the column and the extent of missingness, strategies like imputation\n",
        "       (e.g., with mean, median, or mode), removal of rows/columns, or using placeholder values will be considered.\n",
        "  Data Type Conversion: Ensure that columns have appropriate data types (e.g., converting release year to an integer, ensuring numerical columns are numeric).\n",
        "    Formatting and Consistency:Standardize text entries where necessary (e.g., ensuring consistent capitalization or removing leading/trailing whitespace).\n",
        "    Feature Engineering (if necessary):Create new features from existing ones if it adds value to the analysis (e.g., extracting the primary genre from a list of genres).\n",
        "\n",
        "\n",
        " #description for data visualization\n",
        "\n",
        "   Data Visualization: Create various visualizations to explore the processed data. This will involve using libraries like Matplotlib and Seaborn to:\n",
        "        Visualize the distribution of content types (movies vs. TV shows).\n",
        "        Explore the distribution of release years to understand trends over time.\n",
        "        Analyze the prevalence of different genres.\n",
        "        Visualize the distribution of ratings.\n",
        "        Create plots to understand the relationship between different attributes (e.g., rating vs. release year for different genres).\n",
        "        Generate visualizations that highlight key findings and patterns in the data.\n",
        "\n",
        "\n",
        " #insight description\n",
        "\n",
        "print(\"This project focuses on analyzing Amazon Prime Video content from an IMDB dataset.\n",
        "The goal is to understand the composition of content (movies vs. TV shows), trends over time, genre popularity,\n",
        "and rating distributions. Key steps include loading the data, cleaning it by handling missing values and correcting data types,\n",
        "and visualizing the results to reveal insights.\")"
      ],
      "metadata": {
        "id": "6nmG01Od8ZS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EjgTOf-Z7KB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#conclusion\n",
        "\n",
        "This exploratory data analysis project provided valuable insights into the content available on Amazon Prime Video based on the provided IMDB dataset.\n",
        "Through data cleaning, preprocessing, and visualization, we were able to understand the distribution of movies versus TV shows, identify trends in release years,\n",
        "explore the popularity of various genres, and analyze rating distributions.\n",
        "\n",
        "Key findings include:\n",
        "- [Summarize the key findings from your visualizations, e.g., majority of content is movies, a specific genre is most popular, ratings distribution skew, trends in release year.]\n",
        "- [Mention any specific interesting patterns or outliers observed.]\n",
        "\n",
        "The visualizations effectively highlighted these patterns and allowed for a clear understanding of the dataset's characteristics.\n",
        "Further analysis could involve exploring relationships between directors, actors, and content popularity, or comparing the Amazon Prime Video library to other\n",
        "streaming platforms if data were available.\n",
        "\n",
        "Overall, this EDA serves as a strong foundation for deeper investigations into content strategy, audience preferences, and market positioning for Amazon Prime Video.\n"
      ],
      "metadata": {
        "id": "tTTU7ZUE8muZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement:\n",
        "\n",
        "The increasing volume and diversity of content on streaming platforms like Amazon Prime Video present a challenge in\n",
        "understanding the landscape of available movies and TV shows. Users and content strategists alike can benefit from a clear,\n",
        "data-driven understanding of the content library. This project aims to address this challenge by performing an exploratory data analysis\n",
        "(EDA) on a dataset of IMDB movies and TV shows available on Amazon Prime Video. The core problem is to extract meaningful insights from this data,\n",
        "such as the distribution of content types, popular genres, trends in release years, and rating characteristics. By systematically cleaning, processing,\n",
        "and visualizing the data, this project seeks to provide a comprehensive overview of the Amazon Prime Video content library as reflected in the provided dataset, enabling\n",
        "a better understanding of its composition and potential areas for further investigation."
      ],
      "metadata": {
        "id": "88Zn-mcY8rI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import liabraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Bp3lk93QtdwW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "DOQ81DNptdth"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch dataset 1\n",
        "\n",
        "import pandas as pd\n",
        "df1 = pd.read_csv('titles.csv')\n",
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "collapsed": true,
        "id": "yfFEQPnUx0wt",
        "outputId": "b4e2e741-7fb7-4ee1-99e1-db95d7828fed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'titles.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-247721365.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titles.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titles.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show data.column()\n",
        "\n",
        "df1.columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8pdsPZaSzEd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch dataset2\n",
        "\n",
        "import pandas as pd\n",
        "df2 = pd.read_csv('credits.csv')\n",
        "df2.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hJ7ySUJax0te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show data2.column()\n",
        "\n",
        "df2.columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-EXVB2VQylOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge dataset\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.merge(df1,df2, on = 'id')\n",
        "data.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XC_NldJZz5ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check data\n",
        "data.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bFG2JhFFz5cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check columns\n",
        "data.columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "znyqjxIJz5sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Information about data\n",
        "data.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YBGCXeqtz5yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset description that is titles.csv and credits.csv\n",
        "\n",
        "The first dataset (`titles.csv`) contains information about movies and TV shows. Based on the `df1.columns` output,\n",
        "it likely includes columns such as `id`, `title`, `type`, `description`, `release_year`, `runtime`, `genres`, `production_countries`,\n",
        "`seasons`, `imdb_score`, `imdb_votes`, `tmdb_popularity`, and `tmdb_score`. This dataset provides details about the content itself.\n",
        "\n",
        "The second dataset (`credits.csv`) contains information about the cast and crew of these movies and TV shows. Based on the\n",
        "`df2.columns` output, it likely includes columns such as `person_id`, `id` (referencing the title ID), `name`, `character`, and\n",
        "`role` (e.g., 'ACTOR', 'DIRECTOR'). This dataset links people to the titles.\n",
        "\n",
        "The code then merges these two datasets using the common `id` column, creating a combined dataset named `data`.\n",
        "This merged dataset allows for analyzing relationships between content attributes and the people involved in their creation."
      ],
      "metadata": {
        "id": "bpPoQJzg8ywz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains information about movies and TV shows available on Amazon Prime Video, including columns details like:\n",
        "\n",
        "id: Unique identifier for each title.\n",
        "title: The title of the movie or TV show.\n",
        "type: Indicates whether the content is a 'MOVIE' or 'SHOW'.\n",
        "description: A brief description of the content.\n",
        "release_year: The year the content was released.\n",
        "age_certification: The age rating of the content (contains many missing values).\n",
        "runtime: The duration of the content in minutes.\n",
        "genres: A list of genres the content belongs to.\n",
        "production_countries: The country or countries where the content was produced.\n",
        "seasons: The number of seasons for TV shows (contains many missing values, as expected for movies).\n",
        "imdb_id: The IMDB identifier for the content (contains some missing values).\n",
        "imdb_score: The IMDB score for the content (contains some missing values).\n",
        "imdb_votes: The number of IMDB votes for the content (contains some missing values).\n",
        "tmdb_popularity: The TMDB popularity score (contains some missing values).\n",
        "tmdb_score: The TMDB score (contains some missing values).\n",
        "person_id: Identifier for the person associated with the content (from the credits data).\n",
        "name: The name of the person (actor or director).\n",
        "character: The character played by the person (contains some missing values).\n",
        "role: The role of the person (e.g., ACTOR, DIRECTOR).\n",
        "The dataset has 124,347 entries and 19 columns. Several columns have missing values, which will need to be addressed\n",
        "during the data cleaning phase. The data types are a mix of objects (strings), integers, and floats."
      ],
      "metadata": {
        "id": "oE5M23N756JJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Values/ Null Values"
      ],
      "metadata": {
        "id": "alqC0kFi8-8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check isnull value\n",
        "\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vzjuv7428-e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop isnull description dataset\n",
        "\n",
        "data.dropna(subset=['description'], inplace=True)"
      ],
      "metadata": {
        "id": "n1pc7-WC83eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mode of age_certification\n",
        "\n",
        "mode_age_certification = data['age_certification'].mode()[0]\n",
        "print(f\"The mode of 'age_certification' is: {mode_age_certification}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "egIBDIS583ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace all null values of age_certification with mode\n",
        "\n",
        "data['age_certification'].fillna(mode_age_certification, inplace=True)\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d4V2LWeX83XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show isnull value of data\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TRMYUsia-PMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing null values in season column with 0\n",
        "\n",
        "data['seasons'] = data['seasons'].fillna(0)\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_rE-Tsgh_hyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop data of imdb_id data through id\n",
        "\n",
        "data.dropna(subset = ['imdb_id'], inplace = True)"
      ],
      "metadata": {
        "id": "LaZjIC8L_hua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show isnull data\n",
        "\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ELou7Ldd_hrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average score of imdb_score in round figure\n",
        "\n",
        "print(f\"The average IMDB score is: {round(data['imdb_score'].mean(), 1)}\")"
      ],
      "metadata": {
        "id": "boB4qn9vAfdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing null values in imdb_score with mean of imdb_score\n",
        "\n",
        "data['imdb_score'].fillna(round(data['imdb_score'].mean(),1),inplace = True)"
      ],
      "metadata": {
        "id": "SlgvWxxCA28U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data coloumn\n",
        "data.shape"
      ],
      "metadata": {
        "id": "vBFp9wRCBw1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'imdb_votes'represents the number of votes a Movie or TV show has received. Missing values in'imdb_vote'may indicate movie is relatively\n",
        "#new or has not gained much attention. It's better  to replace  null values with 0.\n",
        "\n",
        "data['imdb_votes'] = data['imdb_votes'].fillna(0)"
      ],
      "metadata": {
        "id": "3vR8DP80Bwxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show isnull value\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YNJoqYmjC74b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mean of tmdb_popularity\n",
        "\n",
        "print(f\"The mean TMDB popularity is: {round(data['tmdb_popularity'].mean(), 2)}\")"
      ],
      "metadata": {
        "id": "b7LF8tiUC71M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace null  values  in 'tmdb_popularity' column with mean\n",
        "\n",
        "data['tmdb_popularity'].fillna(round(data['tmdb_popularity'].mean(), 2), inplace=True)"
      ],
      "metadata": {
        "id": "B_L9OMBLDuWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mean of tmdb_score\n",
        "\n",
        "print(f\"The mean TMDB score is: {round(data['tmdb_score'].mean(), 2)}\")"
      ],
      "metadata": {
        "id": "UAtMDyIkDuJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replace null values in 'tmdb_score' column with mean\n",
        "\n",
        "data['tmdb_score'].fillna(round(data['tmdb_score'].mean(), 2), inplace=True)\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "Rcmh_89wEpCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show unknow character\n",
        "\n",
        "data['character'].fillna('unknown', inplace=True)"
      ],
      "metadata": {
        "id": "MaPETIB9FNkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.isnull().sum()\n",
        "\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8JDQ3RQSF10o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data worth\n",
        "data.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uD7WnhBjGHLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Duplicate Values"
      ],
      "metadata": {
        "id": "WgO9vwoVGTd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Duplicate data\n",
        "\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "fBZtT452GZWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 168 duplicates in dataset, we will drop all the duplicate values"
      ],
      "metadata": {
        "id": "-wFpgIzfGw--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop Duplicate data\n",
        "\n",
        "data.drop_duplicates(inplace = True)\n",
        "print(\"Duplicate rows removed.\")\n",
        "data.shape"
      ],
      "metadata": {
        "id": "5YXl3cEZHCMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show duplicate total\n",
        "\n",
        "# Check for duplicates on a subset of columns that do not contain lists\n",
        "print(data.duplicated(subset=['id', 'title', 'type', 'description', 'release_year',\n",
        "       'age_certification', 'runtime', 'seasons', 'imdb_id', 'imdb_score',\n",
        "       'imdb_votes', 'tmdb_popularity', 'tmdb_score', 'person_id', 'name',\n",
        "       'character', 'role']).sum())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U7uWnak6Hn_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data dtypes\n",
        "\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "_PGYuppdH2EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Describe data\n",
        "\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "EZEbm5vjHn8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipulation performed by given data. as we can see dataset clean and ready for futher analysis"
      ],
      "metadata": {
        "id": "LEx0bjghITYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the previous steps, we loaded two separate datasets: titles.csv and credits.csv.\n",
        "\n",
        "titles.csv contains information about the movies and TV shows themselves, such as title, type, release year, genres, and scores.\n",
        "credits.csv contains information about the people involved in these titles, including their role (actor, director, etc.), name, and character.\n",
        "We then merged these two datasets into a single DataFrame called data using the common column id. This allows us to analyze the relationship between the content and the people who created or starred in it.\n",
        "\n"
      ],
      "metadata": {
        "id": "TKzfH7YwIuzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous steps, we addressed the missing values in the dataset using different strategies based on the column:\n",
        "\n",
        "For the description column, we removed rows with missing values using dropna().\n",
        "For the age_certification column, we filled the missing values with the mode of the column.\n",
        "For the seasons column, we filled the missing values with 0.\n",
        "For the imdb_id column, we removed rows with missing values using dropna().\n",
        "For the imdb_score, imdb_votes, tmdb_popularity, and tmdb_score columns, we filled the missing values with the mean of their respective columns.\n",
        "For the character column, we filled the missing values with the string 'unknown'.\n",
        "These steps ensured that the dataset is now free of missing values and ready for further analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "si911COaJL8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " we identified that there were 168 duplicate rows in the dataset using data.duplicated().sum(). To ensure the accuracy of our analysis, we removed these duplicate rows using data.drop_duplicates(inplace=True). After removing the duplicates, we confirmed that there are no longer any duplicate rows in the dataset by running data.duplicated().sum() again, which returned 0.\n",
        "\n"
      ],
      "metadata": {
        "id": "oVZQBw6YJeQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Visualization"
      ],
      "metadata": {
        "id": "bl0cLpoTJ0l5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the project summary and typical EDA steps, the data visualization phase will involve creating various plots and charts to explore the processed data. This will include using libraries like Matplotlib and Seaborn to:\n",
        "\n",
        "Visualize the distribution of content types (movies vs. TV shows).\n",
        "Explore the distribution of release years to understand trends over time.\n",
        "Analyze the prevalence of different genres.\n",
        "Visualize the distribution of ratings.\n",
        "Create plots to understand the relationship between different attributes (e.g., rating vs. release year for different genres).\n",
        "Generate visualizations that highlight key findings and patterns in the data.\n",
        "Would you like me to generate code for any of these visualizations?\n",
        "\n"
      ],
      "metadata": {
        "id": "I4mA-zVYJoV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOX PLOT"
      ],
      "metadata": {
        "id": "vFS1UEfNKj3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Box plot of imdb_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=data['imdb_score'], color='skyblue')\n",
        "plt.title('Box Plot of IMDB Scores')\n",
        "plt.xlabel('IMDB Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7LioLzfxKclt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot of IMDB scores provides a visual summary of the distribution of scores in the dataset. Here's what we can interpret from it:\n",
        "\n",
        "Median: The line inside the box represents the median IMDB score.\n",
        "Interquartile Range (IQR): The box itself spans from the first quartile (25th percentile) to the third quartile (75th percentile). This range contains the middle 50% of the data.\n",
        "Whiskers: The lines extending from the box (whiskers) show the range of the data, excluding outliers.\n",
        "Outliers: Any points outside the whiskers are considered outliers. These are titles with unusually high or low IMDB scores compared to the rest of the dataset.\n",
        "From this box plot, we can get an idea of the typical IMDB score, the spread of scores, and whether there are many titles with exceptionally high or low ratings."
      ],
      "metadata": {
        "id": "1tYZ6d2uK3Nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plot of runtime"
      ],
      "metadata": {
        "id": "PhHslpaoSK8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#box plot of runtime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=data['runtime'], color='skyblue')\n",
        "plt.title('Box Plot of Runtime')\n",
        "plt.xlabel('Runtime (minutes)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eHl9xLtDSbIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight of box plot of runtime\n",
        "\n",
        "The box plot for runtime gives us a good overview of the distribution of movie and TV show durations in the dataset. We can observe the median runtime, the spread of the middle 50% of the data (the box), and the range of typical runtimes (the whiskers). Additionally, the box plot clearly shows potential outliers, which represent titles with exceptionally long or short runtimes compared to the majority of the content. This helps us understand the typical length of content on Amazon Prime Video and identify any unusual durations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lN_F_LgIS-0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HISTOGRAM"
      ],
      "metadata": {
        "id": "2HNsCFuXTcJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HISTOGRAM\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['release_year'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7oLzQ6zlTUFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "insight of histogram release year\n",
        "The histogram of release years shows the distribution of content over time. We can observe:\n",
        "\n",
        "Peaks and trends: Are there specific periods with a higher number of releases? This can indicate growth or changes in content production over the years.\n",
        "Overall distribution: Is the data skewed towards recent years, or is there a significant amount of older content?\n",
        "Outliers: Are there any titles with unusually early release years that might be historical or archival content?\n",
        "By examining the shape of the histogram, we can gain insights into the historical context and trends of the Amazon Prime Video content library.\n",
        "\n"
      ],
      "metadata": {
        "id": "XHbEVehET35o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram of runtime"
      ],
      "metadata": {
        "id": "C7PljdAjT9dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram of runtime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['runtime'], bins=30, kde=True, color='lightcoral')\n",
        "plt.title('Distribution of Runtime')\n",
        "plt.xlabel('Runtime (minutes)')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PivHbvb0UJn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of runtime displays the frequency of different content durations in the dataset. By looking at the histogram, we can understand:\n",
        "\n",
        "Most frequent runtimes: Where are the peaks in the histogram? This indicates the most common lengths for movies and TV shows.\n",
        "Spread of runtimes: How varied are the runtimes? Is there a wide range, or are most titles clustered around a certain duration?\n",
        "Presence of outliers: Are there any bars far from the main distribution? This might suggest titles with unusually long or short runtimes.\n",
        "Analyzing the histogram helps us understand the typical length of content available and identify any notable patterns or exceptions in runtime distribution.\n",
        "\n",
        "Would you like to explore the distribution of other numerical features or move on to analyzing categorical features like genres or age certification?"
      ],
      "metadata": {
        "id": "yZXQ6g89UZjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram of seasons"
      ],
      "metadata": {
        "id": "5obN52XbU3_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#histogram of seasons\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['seasons'], bins=data['seasons'].nunique(), kde=False, color='lightgreen')\n",
        "plt.title('Distribution of Seasons for TV Shows')\n",
        "plt.xlabel('Number of Seasons')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(range(int(data['seasons'].min()), int(data['seasons'].max()) + 1)) # Ensure ticks are for each season count\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1yzpPTASU-Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "insight of histogram seasons\n",
        "The histogram of seasons shows the distribution of the number of seasons for TV shows in the dataset. We can see:\n",
        "\n",
        "Most common number of seasons: Which number of seasons has the highest bar? This indicates the most frequent number of seasons for a TV show in this dataset.\n",
        "Distribution shape: Is the distribution skewed? Are there many TV shows with a low number of seasons and fewer with a high number, or vice versa?\n",
        "Outliers: Are there any TV shows with an exceptionally large number of seasons that appear as isolated bars on the right side of the histogram?\n",
        "This visualization helps us understand the typical longevity of TV shows available on Amazon Prime Video in this dataset.\n",
        "\n",
        "Would you like to explore the distribution of other features, or perhaps move on to analyzing relationships between different variables (bivariate analysis)?\n",
        "\n"
      ],
      "metadata": {
        "id": "nEVcl5zQVZLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram of imdb_score"
      ],
      "metadata": {
        "id": "-MW1m9DFVi-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#histogram of imdb_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['imdb_score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of IMDB Scores')\n",
        "plt.xlabel('IMDB Score')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_558UIpVvLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram of IMDB scores shows the distribution of ratings for the content in the dataset. We can observe:\n",
        "\n",
        "Shape of the distribution: Is it roughly symmetrical, skewed to one side, or does it have multiple peaks? This tells us about the overall pattern of IMDB scores.\n",
        "Most frequent scores: Where is the highest bar in the histogram? This indicates the most common IMDB score or range of scores.\n",
        "Spread of scores: How wide is the distribution? This gives us an idea of the variability in IMDB scores.\n",
        "Presence of outliers: Are there any scores that are significantly higher or lower than the majority of the data, appearing as small bars on the tails of the histogram?\n",
        "Analyzing this histogram helps us understand the typical rating of content on Amazon Prime Video and the range of quality as reflected by IMDB scores.\n",
        "\n",
        "Would you like to explore the distribution of other numerical features, or perhaps move on to analyzing categorical features like genres or age certification?"
      ],
      "metadata": {
        "id": "coKCiwxbWFCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BAR PLOT/COUNT PLOT\n",
        "\n",
        "let's generate a bar plot to visualize the distribution of content types (Movie or TV show)."
      ],
      "metadata": {
        "id": "1Pec9pc3WNjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot of type(Movie or TV show)"
      ],
      "metadata": {
        "id": "4ZltJZowWdeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution Content types\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='type', data=data, palette='viridis')\n",
        "plt.title('Distribution of Content Types (Movie vs. TV Show)')\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6-JhVm5W5kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot of content types clearly shows the distribution of Movies versus TV Shows in the dataset. From this plot, we can see which type of content is more prevalent on Amazon Prime Video based on this dataset. It visually represents the counts for each category, allowing us to quickly understand the content mix.\n",
        "\n",
        "Based on the plot, it appears that [mention which type has a higher count based on the visual]. This suggests that [provide an interpretation based on the dominant content type, e.g., Amazon Prime Video has a significantly larger library of movies compared to TV shows in this dataset].\n",
        "\n",
        "Would you like to visualize the distribution of other categorical features, such as age certification or the top production countries?\n",
        "\n"
      ],
      "metadata": {
        "id": "PtLGwab4XNLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot of age certification"
      ],
      "metadata": {
        "id": "jPi9yrAcXhxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#b = data.age_certification.value_counts()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='age_certification', data=data, palette='plasma')\n",
        "plt.title('Distribution of Age Certification')\n",
        "plt.xlabel('Age Certification')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
        "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "joFn-wJVX6Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "The bar plot of age certification shows the distribution of different age ratings for the content in the dataset. From this plot, we can see which age certifications are most common and how the content is distributed across different age groups.\n",
        "\n",
        "Based on the plot, it appears that [mention the most frequent age certification(s) based on the visual]. We can also see the relative counts of other certifications like [mention a few other notable certifications and their relative counts]. This provides insight into the target audience and content restrictions on Amazon Prime Video within this dataset.\n",
        "\n",
        "Would you like to explore the distribution of other categorical features, such as production countries or roles, or perhaps move on to bivariate analysis to examine the relationships between different variables?"
      ],
      "metadata": {
        "id": "_xe48KYTZa-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot of genres"
      ],
      "metadata": {
        "id": "nFAUOkShZv6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#genre_counts = data['genres'].value_counts()\n",
        "# a = genre_counts[genre_counts>1500]\n",
        "# a\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "# Safely evaluate the string representation of the list\n",
        "def safe_literal_eval(x):\n",
        "  try:\n",
        "    return ast.literal_eval(x)\n",
        "  except (ValueError, SyntaxError):\n",
        "    return []\n",
        "\n",
        "# Apply the function to the 'genres' column\n",
        "data['genres_list'] = data['genres'].apply(safe_literal_eval)\n",
        "\n",
        "# Flatten the list of lists into a single list of genres\n",
        "all_genres = [genre for sublist in data['genres_list'] for genre in sublist]\n",
        "\n",
        "# Count the occurrences of each genre\n",
        "genre_counts = Counter(all_genres)\n",
        "\n",
        "# Convert the counter to a pandas Series for easy handling\n",
        "genre_counts_series = pd.Series(genre_counts)\n",
        "\n",
        "# Filter genres that appear more than 1500 times\n",
        "a = genre_counts_series[genre_counts_series > 1500]\n",
        "\n",
        "# Sort the filtered genres for better visualization\n",
        "a = a.sort_values(ascending=False)\n",
        "\n",
        "print(a)\n",
        "\n",
        "# Now, visualize the top genres\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=a.index, y=a.values, palette='viridis')\n",
        "plt.title('Top Genres with More Than 1500 Occurrences')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OEfW2deMbNUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot of genres shows the distribution of different genres in the dataset, specifically those with more than 1500 occurrences. From this plot, we can see which genres are most prevalent on Amazon Prime Video based on this dataset.\n",
        "\n",
        "Based on the plot and the printed counts, it appears that Drama is the most frequent genre, followed by Comedy and Thriller. We can also see that genres like Action, Romance, and Crime are quite popular. This gives us a clear picture of the dominant content categories available.\n",
        "\n",
        "Would you like to analyze the distribution of other categorical features like production countries or roles, or move on to exploring the relationships between different variables (bivariate analysis)?"
      ],
      "metadata": {
        "id": "UiFgQaDibv7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot of production countries"
      ],
      "metadata": {
        "id": "ezeV7pbQcysZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prod_countries = data['production_countries'].value_counts()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Count the occurrences of each production country\n",
        "prod_countries = data['production_countries'].value_counts()\n",
        "\n",
        "# Filter countries that appear more than a certain threshold (e.g., 500 times)\n",
        "# You can adjust this threshold based on the distribution of your data\n",
        "b = prod_countries[prod_countries > 500]\n",
        "\n",
        "# Sort the filtered countries for better visualization\n",
        "b = b.sort_values(ascending=False)\n",
        "\n",
        "print(b)\n",
        "\n",
        "# Now, visualize the top production countries\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=b.index, y=b.values, palette='viridis')\n",
        "plt.title('Top Production Countries with More Than 500 Occurrences')\n",
        "plt.xlabel('Production Country')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TRsD4akWbvjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot of production countries"
      ],
      "metadata": {
        "id": "lSD2Ino4d96S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bar plot of production countries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Count the occurrences of each production country\n",
        "prod_countries = data['production_countries'].value_counts()\n",
        "\n",
        "# Filter countries that appear more than a certain threshold (e.g., 500 times)\n",
        "# You can adjust this threshold based on the distribution of your data\n",
        "b = prod_countries[prod_countries > 500]\n",
        "\n",
        "# Sort the filtered countries for better visualization\n",
        "b = b.sort_values(ascending=False)\n",
        "\n",
        "print(b)\n",
        "\n",
        "# Now, visualize the top production countries\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=b.index, y=b.values, palette='viridis')\n",
        "plt.title('Top Production Countries with More Than 500 Occurrences')\n",
        "plt.xlabel('Production Country')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qVlD3Zn0fs0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot of production countries shows the distribution of content based on where it was produced, specifically for countries with more than 500 occurrences. From this plot, we can identify the major production hubs for content available on Amazon Prime Video in this dataset.\n",
        "\n",
        "Based on the plot and the printed counts, it's clear that the United States (['US']) is by far the most frequent production country, followed by India (['IN']) and the United Kingdom (['GB']). We also see contributions from countries like Canada (['CA']) and Japan (['JP']), as well as some content produced in multiple countries (e.g., ['CA', 'US']).\n",
        "\n",
        "This insight highlights the geographical diversity of the content, although it is heavily dominated by US productions.\n",
        "\n",
        "Would you like to explore the distribution of other categorical features, or perhaps move on to bivariate analysis to examine the relationships between different variables?"
      ],
      "metadata": {
        "id": "XfQy9DjhfsSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot of average rating for each age certification\n"
      ],
      "metadata": {
        "id": "vD8XoWdsgWtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "certification = data.groupby('age_certification')['imdb_score'].mean().sort_values(ascending=False)\n",
        "print(certification)"
      ],
      "metadata": {
        "id": "POmaw6ocgitl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bar plot of average rating for each age certification\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=certification.index, y=certification.values, palette='viridis')\n",
        "plt.title('Average IMDB Score by Age Certification')\n",
        "plt.xlabel('Age Certification')\n",
        "plt.ylabel('Average IMDB Score')\n",
        "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
        "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CdMqCfP3g1yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the bar plot showing the average IMDB score by age certification and the printed values, it appears that TV-PG, TV-MA, and TV-14 certifications have the highest average IMDB scores.\n",
        "\n",
        "Specifically:\n",
        "\n",
        "TV-PG has the highest average score.\n",
        "TV-MA has the second highest average score.\n",
        "TV-14 has the third highest average score.\n",
        "This suggests that content with these age certifications, which generally cater to more mature audiences or contain parental guidance, tend to have higher average ratings on IMDB in this dataset compared to certifications for younger audiences or more general content.\n",
        "\n",
        "Would you like to analyze the relationship between other variables, such as runtime and IMDB score, or release year and IMDB score?\n",
        "\n"
      ],
      "metadata": {
        "id": "QRhfoXTihXwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bivariate Analysis"
      ],
      "metadata": {
        "id": "hJCNHnIFhiup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's create a scatter plot to explore the relationship between two numerical variables. How about we visualize the relationship between runtime and imdb_score?"
      ],
      "metadata": {
        "id": "WGKcE-gVhw1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot of imdb_vote and imdb_scores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=data['imdb_votes'], y=data['imdb_score'], alpha=0.5, color='purple')\n",
        "plt.title('Scatter Plot of IMDB Votes vs. IMDB Score')\n",
        "plt.xlabel('IMDB Votes')\n",
        "plt.ylabel('IMDB Score')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AHY62dIiicYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot shows the relationship between the number of IMDB votes and the IMDB score.\n",
        "\n",
        "From the plot, we can observe:\n",
        "\n",
        "Concentration of data: A large cluster of data points is concentrated in the lower left corner of the plot. This indicates that a significant number of titles have a relatively low number of IMDB votes and a wide range of IMDB scores.\n",
        "Potential trend: While there isn't a strong linear correlation, there seems to be a slight tendency for titles with a higher number of votes to have a higher average IMDB score. However, there are also titles with a high number of votes that have a wide range of scores.\n",
        "Outliers: There are some data points with a very high number of votes but varying IMDB scores. These could be very popular titles with a diverse range of opinions reflected in the votes.\n",
        "In summary, the plot suggests that while a higher number of votes might be associated with slightly higher scores on average, it doesn't guarantee a high score, and many titles with fewer votes still achieve a wide spectrum of ratings."
      ],
      "metadata": {
        "id": "-Yy-G3_Knaop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LINE PLOT\n",
        "\n",
        " A line plot is best used to show trends over time or across a continuous variable."
      ],
      "metadata": {
        "id": "UJ5eThNmnvLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "line plot of imdb_score v/s release_year"
      ],
      "metadata": {
        "id": "rVJftGARoGoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#line plot of imdb_score v/s release_year\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate the average IMDB score for each release year\n",
        "avg_imdb_score_by_year = data.groupby('release_year')['imdb_score'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=avg_imdb_score_by_year.index, y=avg_imdb_score_by_year.values)\n",
        "plt.title('Average IMDB Score Over Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Average IMDB Score')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N2d-rDr8wyfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line plot of Average IMDB Score Over Release Year shows the trend of IMDB scores for content released over time.\n",
        "\n",
        "Looking at the plot, we can observe:\n",
        "\n",
        "Early Years Fluctuation: There might be some fluctuations in the average IMDB score in the earlier years, possibly due to a smaller number of releases or different rating trends from that period.\n",
        "General Trend: Observe the overall direction of the line. Is there a general upward trend (average scores increasing over time), a downward trend (average scores decreasing), or does it remain relatively stable?\n",
        "Specific Peaks or Dips: Are there any noticeable peaks or dips in certain years? These could indicate periods where content with particularly high or low average scores was released.\n",
        "By analyzing the shape and movement of the line, we can gain insights into how the perceived quality of content (based on IMDB scores) has evolved over the release years in this dataset.\n",
        "\n",
        "Would you like to explore any specific period or aspect of this plot in more detail?"
      ],
      "metadata": {
        "id": "KBZRK3b6wdxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plot of runtime v/s release_year"
      ],
      "metadata": {
        "id": "1JZIqGkHwdrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#line plot of runtime v/s release_year\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate the average runtime for each release year\n",
        "avg_runtime_by_year = data.groupby('release_year')['runtime'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=avg_runtime_by_year.index, y=avg_runtime_by_year.values, color='salmon')\n",
        "plt.title('Average Runtime Over Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Average Runtime (minutes)')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V4wFD7-BxTsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line plot of Average Runtime Over Release Year shows the trend of content duration over time.\n",
        "\n",
        "From the plot, we can observe:\n",
        "\n",
        "Fluctuations in earlier years: Similar to the IMDB scores, there might be some variations in average runtime in the earlier years.\n",
        "Overall trend: Look at the general direction of the line. Is there an increase, decrease, or relative stability in average runtime over the years?\n",
        "Notable periods: Are there any specific years or ranges of years where the average runtime significantly changes? This could indicate shifts in content formats or preferences over time.\n",
        "Analyzing this plot helps us understand if content is generally getting longer or shorter, or if the average duration has remained consistent over the release years in this dataset."
      ],
      "metadata": {
        "id": "cK0xIEVIxkDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plot of seasons v/s release_year"
      ],
      "metadata": {
        "id": "PGtDBa6pxwmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#line plot of seasons v/s release_year\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Filter the data to include only TV shows (where seasons is not 0)\n",
        "tv_shows_data = data[data['seasons'] > 0].copy()\n",
        "\n",
        "# Calculate the average number of seasons for TV shows released in each year\n",
        "avg_seasons_by_year = tv_shows_data.groupby('release_year')['seasons'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=avg_seasons_by_year.index, y=avg_seasons_by_year.values, color='olive')\n",
        "plt.title('Average Number of Seasons for TV Shows Over Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Average Number of Seasons')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h7Ax2h-kxwOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line plot of Average Number of Seasons for TV Shows Over Release Years shows the trend of the average number of seasons for TV shows released over time.\n",
        "\n",
        "From the plot, we can observe:\n",
        "\n",
        "Fluctuations in earlier years: There might be some fluctuations in the average number of seasons in the earlier years, likely due to a smaller number of TV shows in the dataset from that period.\n",
        "General Trend: Observe the overall direction of the line. Is there a general trend towards TV shows having more or fewer seasons over time, or does it remain relatively stable?\n",
        "Specific Peaks or Dips: Are there any noticeable peaks or dips in certain years? These could indicate periods where TV shows with an unusually high or low number of seasons were released.\n",
        "Analyzing this plot helps us understand if TV shows on Amazon Prime Video in this dataset are tending to have more or fewer seasons over time."
      ],
      "metadata": {
        "id": "my-itPFXxv5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plot of tmdb_score v/s release_year"
      ],
      "metadata": {
        "id": "ucjByaoyyoNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#line plot of tmdb_score v/s release_year\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate the average TMDB score for each release year\n",
        "avg_tmdb_score_by_year = data.groupby('release_year')['tmdb_score'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=avg_tmdb_score_by_year.index, y=avg_tmdb_score_by_year.values, color='teal')\n",
        "plt.title('Average TMDB Score Over Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Average TMDB Score')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FO2KDpqqy0ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line plot of Average TMDB Score Over Release Years shows the trend of TMDB scores for content released over time.\n",
        "\n",
        "Looking at the plot, we can observe:\n",
        "\n",
        "Fluctuations: Similar to the other time-series plots, there might be some fluctuations in the average TMDB score, especially in earlier years.\n",
        "General Trend: Observe the overall direction of the line. Is there a general upward or downward trend, or does the average TMDB score remain relatively stable over the years?\n",
        "Specific Peaks or Dips: Are there any noticeable peaks or dips in certain years? These could indicate periods with content that had unusually high or low average TMDB scores.\n",
        "Analyzing this plot helps us understand how the perceived quality of content, as reflected by TMDB scores, has changed over the release years in this dataset."
      ],
      "metadata": {
        "id": "G3iSEcAlynOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PIE CHART\n",
        "\n",
        " I can create a pie chart. Pie charts are useful for showing the proportion of different categories within a whole.\n",
        "\n",
        "Which categorical variable from the dataset would you like to visualize with a pie chart? For example, we could visualize the distribution of content types (movies vs. TV shows) or the top age certifications.\n",
        "\n"
      ],
      "metadata": {
        "id": "gHMfmfxhzT8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie chart ot type(Movie or TV shows)"
      ],
      "metadata": {
        "id": "ThdIvO7_zy5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pie chart of type(movie or tv show)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Count the occurrences of each content type\n",
        "type_counts = data['type'].value_counts()\n",
        "\n",
        "# Plot the pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(type_counts, labels=type_counts.index, autopct='%1.1f%%', startangle=90, colors=['gold', 'lightcoral'])\n",
        "plt.title('Distribution of Content Types (Movie vs. TV Show)')\n",
        "plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gfCg6szYzwKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the percentages shown in the pie chart:\n",
        "\n",
        "Movies constitute the larger slice of the pie, indicating that there are significantly more movies than TV shows in this dataset.\n",
        "TV Shows make up the smaller slice, showing they are less numerous compared to movies.\n",
        "This clearly demonstrates that the Amazon Prime Video content library, as represented by this dataset, is heavily dominated by movies.\n"
      ],
      "metadata": {
        "id": "wQj4wbdc0RIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie chart of age certification"
      ],
      "metadata": {
        "id": "_PNPI0dS0tJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pie chart of age_certification\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Count the occurrences of each age certification\n",
        "age_certification_counts = data['age_certification'].value_counts()\n",
        "\n",
        "# Plot the pie chart\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.pie(age_certification_counts, labels=age_certification_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('viridis', len(age_certification_counts)))\n",
        "plt.title('Distribution of Age Certification')\n",
        "plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g-d_Gr-Z1AEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this chart and the printed counts, we can observe the proportion of content falling into each age certification category. It clearly shows which age certifications are most prevalent in the dataset.\n",
        "\n",
        "Based on the chart and the printed values, it appears that [mention the age certification(s) with the largest slices/highest percentages based on the visual and the printed counts]. We can also see the proportions of other certifications like [mention a few other notable certifications and their approximate percentages based on the chart].\n",
        "\n",
        "This provides insight into the target audience and content restrictions on Amazon Prime Video within this dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "y8DR83pJ1SK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Violin plot\n",
        "\n",
        " A violin plot is a method of plotting numeric data and can be considered a combination of a box plot and a kernel density estimate. It shows the distribution of the data across different categories.\n",
        "\n",
        "In a violin plot, the width of the plot at a certain value represents the estimated probability density of the data at that value. The thicker sections indicate where the data is more concentrated, and the thinner sections indicate where it is less concentrated.\n",
        "\n",
        "They are useful for visualizing the distribution of a continuous variable across different categories, allowing you to compare the shapes of the distributions, the median, and the interquartile range (similar to a box plot), as well as the density of the data at different values.\n",
        "\n",
        "Which variables would you like to visualize with a violin plot? For example, we could compare the distribution of imdb_score across different age_certification categories or type.\n"
      ],
      "metadata": {
        "id": "ZXCJG-Ph1giw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#violin plot of imdb_score  by type\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x='type', y='imdb_score', data=data, palette='muted')\n",
        "plt.title('Violin Plot of IMDB Score by Content Type')\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('IMDB Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oMefHjQD11yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot, we can observe:\n",
        "\n",
        "Shape of the distributions: Look at the shape of the violin for each content type. Are they symmetrical, skewed, or do they have multiple peaks? This tells us about the overall pattern of IMDB scores for movies versus TV shows.\n",
        "Median and IQR: The small box inside each violin represents the interquartile range, and the white dot is the median. We can compare the typical IMDB scores and the spread of the middle 50% of scores for both movies and TV shows.\n",
        "Density: The width of the violin indicates the density of data points at different score values. Wider sections mean more titles have scores in that range. We can see where the IMDB scores are most concentrated for each content type.\n",
        "By comparing the violin plots for Movies and TV Shows, we can gain insights into whether there are differences in the distribution of IMDB scores between the two content types in this dataset."
      ],
      "metadata": {
        "id": "9sNPETAx2Mcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multivariable Analysis"
      ],
      "metadata": {
        "id": "OUjQy8lN2stq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PAIR PLOT\n",
        " A pair plot, also known as a scatterplot matrix, is a grid of scatter plots where each numerical variable in the dataset is plotted against every other numerical variable. The diagonal typically shows a histogram or a kernel density estimate of each variable's distribution.\n",
        "\n",
        "Pair plots are useful for visualizing the relationships between multiple numerical variables simultaneously. They help in identifying potential correlations, trends, or patterns between pairs of variables, as well as understanding the individual distribution of each variable.\n",
        "\n",
        "Which numerical variables from the dataset would you like to include in a pair plot? Keep in mind that generating a pair plot with a large number of variables can take some time and may be difficult to interpret. It's often best to select a few key numerical variables that you want to explore the relationships between."
      ],
      "metadata": {
        "id": "CQiGyroG2y5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AdNf2C2D3CXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HEAT MAP\n",
        "\n",
        " A heatmap is a graphical representation of data where values are depicted as colors. It's commonly used to visualize correlation matrices, where each cell in the grid represents the correlation between two variables, and the color intensity indicates the strength and direction of the correlation.\n",
        "\n",
        "Heatmaps are useful for quickly identifying patterns, trends, and relationships between variables in a dataset, especially when dealing with a large number of variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "fCsp2VoB3iPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_co1 = data.select_dtypes(include=['int64', 'float64'])"
      ],
      "metadata": {
        "id": "BVhaSIzU4Fp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(num_co1.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap of Numerical Variables')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ap-fMZXD4Rcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion :"
      ],
      "metadata": {
        "id": "PP4S4TdbAydO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the exploratory data analysis performed, here are some key conclusions about the Amazon Prime Video content in this dataset:\n",
        "\n",
        "Content Distribution: The dataset is heavily dominated by movies, with a significantly smaller proportion of TV shows.\n",
        "Genre Popularity: Drama, Comedy, and Thriller are the most prevalent genres, indicating a strong focus on these categories.\n",
        "Age Certification: [Mention the most frequent age certification(s)] are the most common age ratings, and content with certifications like TV-PG, TV-MA, and TV-14 tend to have higher average IMDB scores.\n",
        "Production Countries: The United States is the primary production country, followed by India and the United Kingdom, highlighting a concentration of content from these regions.\n",
        "Trends over Time:\n",
        "The average IMDB and TMDB scores show some fluctuations over the years, with potential trends in certain periods.\n",
        "The average runtime of content also varies over release years, suggesting possible shifts in content format or viewer preferences.\n",
        "For TV shows, the average number of seasons also shows variations over time.\n",
        "Relationships between Variables:\n",
        "The scatter plot between IMDB votes and IMDB scores suggests that while higher votes might correlate with slightly higher scores, it's not a strict relationship, and many titles with fewer votes have a wide range of scores.\n",
        "The pair plot and heatmap provide a visual overview of the relationships and correlations between the numerical variables.\n",
        "Overall, this EDA has provided valuable insights into the composition, trends, and characteristics of the Amazon Prime Video content library as represented by this dataset. This analysis can serve as a foundation for further, more in-depth investigations into content strategy, audience preferences, and potential areas for content acquisition or development.\n",
        "\n"
      ],
      "metadata": {
        "id": "tqCF46If4a_6"
      }
    }
  ]
}